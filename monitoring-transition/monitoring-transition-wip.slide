Monitoring transition

Saurabh Hirani
@sphirani
saurabhhirani@bluejeansnet.com

* 

.image images/sardonic-server-switch-off-phones.png 

* Problem

- What does it take to move from manual to automated to distributed monitoring?

* Infrastructure in context

- AWS
- VMware
- Network devices
- Third party services
- All of the above in multiple environments

* Pre-nirvana setup

- One big, bad nagios host monitoring everything
- Thousands of hosts, tens of thousands of checks
- Hosts, hostgroups, checks, scripts added manually
- Configs scattered through the filesystem
- Developers raise monitoring tickets with each release

* Face it

- It works

* Because...

.image images/sardonic-server-users.png

* The price

- How do I add 100 new hosts in an environment?
- How do I get to know about decomissioned hosts?
- How do I monitor dynamic environments - AWS autoscaling groups?
- Why do I need to write 95% similar code for two similar checks?
- We added 2 new switches - are they monitored?

* Don't even get started on

- Runbooks
- High availability
- Distributed checks
- REST APIs to build tools on
- Non OPS perspectives

* Why don't you just...

- Use chef, puppet, etc. to pull out all the information?
- Use a CMDB?
- Use X tool? - it's so nice and shiny

* Debunking

- Everything is not cheffed e.g. network devices, snowflakes
- CMDB - if you had a good one - you wouldn't be in this mess
- Will tool X cleanup the manually maintained mess? If yes, go for it!

* The hard truth

- Realize that monsters are not born - they are created
- Buckle up and clean up the mess
- Finish what you start

* Better said than done

- Monitoring systems don't have a downtime
- Transparent cutover expected
- Show measurable progress

* What you are really solving

- Audit - Is everything "monitorable"?
- Cleanup - Finding and killing stale nodes, redundant servers
- Rinse, repeat == everything is monitorable

* Revisit your monitoring strategy

- Monitor hosts where X == Y
- Equally important ignore hosts where A == B
- Pull data from multiple DBs (Chef, AWS, etc.)
- Different levels of grouping - location, functionality, product, etc.
- Choice: icinga2 for above reasoning

* Black box to break

- Build a parallel setup and cutover

* Where do I start?

- Take stock - write dirty scripts, glue code, do what it takes
- Categorize - hosts, hostgroups, checks, environments
- Demo: nagios-api, nagira

* Charity begins at home

- Consolidate server side checks
- Distribute client side checks
- Package your plugins and their configs
- == A server with no checks but everything that's needed to run them.
- Demo: dockerized fpm

* Everything is not everywhere

- Config management systems - chef, puppet, etc
- Cloud providers - AWS, VMWare, etc
- CMDB prelimnary population - Device42
- Manual - ignore or fix and forget
- Notes to bring it all under one roof

* One life is too short to write boilerplate json

- HTTP codes are a feature
- I am no microservices expert but I want uniform uris
- Good time to decide on metrics to monitor
- Demo: jsonalyzer

* Buy in on what you can break

- No one has a single qa, stage, prod
- Multiple environments to cutover from
- Target the low hanging fruits

* Homework done till now

- A clean server raring to go
- Know how on what to pull from where
- Standardized and categorized checks
- First target environment

* Heads down, execution time

- One DB at a time - Chef, AWS, etc.
- Demo: icinga2 cookbook basic structure

* Progressive cutover

- One environment a time. 
- Demo: nagios-api disable active checks demo
- Go back to the previous slide

* Futureproof - Detect manual errors

- Violaters violate
- Abiders abide
- Fixers fix
- Show me the numbers!
- Demo: inframer rule checkers

* Monitor the monitor

.image images/sardonic-server-resources.png

* Distributed checks

- Out of the box in icinga2
- If you designed the previous steps correctly, horizontal scalability is a side effect
- Distributed monitoring != Distributed checks

* The fun stuff

- Chat bots - hubot, lita, errbot
- Meta checks - runbook alerts, inframer rules
- REST API tools - upgrades, downtimes, ASG monitoring
.link https://github.com/saurabh-hirani/icinga2-api-examples icinga2-api-examples
.link https://github.com/saurabh-hirani/icinga2_api icinga2_api

* Conclusion

- Cleanup is insightful
- Automate for the maintainers 
- Catch yourself cheating
- The rent is due everyday

* Thank you - Q & A
